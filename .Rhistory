mean_trip_data<-mean_trip_data  %>% data.table::as.data.table() %>%
.[,lapply(.SD, mean), by = c("date_parsed","mode", "tripid"), .SDcols = all_vars]
# multiply the average trip probability in the new scenario (probA) by each catch variable to get probability-weighted catch
list_names <- c("tot_keep_sf_new",   "tot_rel_sf_new",  "tot_cat_sf_new",
"tot_keep_bsb_new",  "tot_rel_bsb_new", "tot_cat_bsb_new",
"tot_keep_scup_new","tot_rel_scup_new",  "tot_cat_scup_new")
all_vars <- c(list_names)
mean_trip_data <- mean_trip_data %>%
data.table::as.data.table() %>%
.[,as.vector(all_vars) := lapply(.SD, function(x) x * probA), .SDcols = all_vars] %>%
.[]
## select the same number of choice occasions in the prediction year as in the calibration year
# We will multiply each simulated choice equation by an appropriate expansion factor,
# then multiply this expansion factor by the projection-year calendar adjustment to account for
# different numbers of weekend vs. weekday in the projection year versus the calibration
ndraws = 50
mean_trip_data<-mean_trip_data %>%
dplyr::left_join(n_choice_occasions, by = c("mode", "date_parsed")) %>%
dplyr::mutate(month = lubridate::month(date_parsed))  %>%
dplyr::mutate(dplyr::across(where(is.numeric), ~tidyr::replace_na(., 0))) %>%  #replace NAs for n_choice_occasions and estimated trips
dplyr::left_join(calendar_adjustments, by = c("mode", "month")) %>%
dplyr::rename(n_choice_occasions0=n_choice_occasions,
estimated_trips0=estimated_trips) %>%
dplyr::mutate(n_choice_occasions=n_choice_occasions0*expansion_factor,
expand=n_choice_occasions/ndraws)
# Expand outcomes for projection year
list_names <- c("tot_keep_sf_new",   "tot_rel_sf_new",  "tot_cat_sf_new",
"tot_keep_bsb_new",  "tot_rel_bsb_new", "tot_cat_bsb_new",
"tot_keep_scup_new","tot_rel_scup_new",  "tot_cat_scup_new",
"probA", "change_CS")
all_vars <- c(list_names)
mean_trip_data <- mean_trip_data %>%
data.table::as.data.table() %>%
.[,as.vector(all_vars) := lapply(.SD, function(x) x * expand), .SDcols = all_vars] %>%
.[]
#retain expansion factors by strata to multiply with length data
expansion_factors<-mean_trip_data %>%
dplyr::select("date_parsed","mode", "tripid", "expand")
#process length data
pattern_vars <- grep("^keep_(sf_|bsb_|scup_)[0-9.]*$|^release_(sf_|bsb_|scup_)[0-9.]*$",
names(length_data), value = TRUE)
length_data<-length_data  %>% data.table::as.data.table() %>%
.[,lapply(.SD, mean), by = c("date_parsed","mode", "tripid"), .SDcols = pattern_vars]
length_data<-length_data %>%
dplyr::right_join(expansion_factors, b=c("date_parsed","mode", "tripid"))
length_data <- length_data %>%
data.table::as.data.table() %>%
.[,as.vector(pattern_vars) := lapply(.SD, function(x) x * expand), .SDcols = pattern_vars] %>%
.[]
## Compute welfare and predicted trips
# Aggregate by mode
mean_trip_data <- mean_trip_data %>%
dplyr::rename(n_trips_alt = probA)
# Ensure mean_trip_data is a data.table
data.table::setDT(mean_trip_data)
list_names <- c("change_CS","n_trips_alt")
aggregate_trip_data_mode <- mean_trip_data[, lapply(.SD, sum), by = .(mode), .SDcols = list_names]
# Aggregate for all modes
aggregate_trip_data_allmodes <- mean_trip_data[, lapply(.SD, sum), .SDcols = list_names][
, mode := "all modes"
]
# Combine and reshape
model_output1 <- rbindlist(list(aggregate_trip_data_mode, aggregate_trip_data_allmodes), use.names=TRUE)
model_output1_long <- melt(
model_output1,
id.vars = c("mode"),   # keep these as identifiers
measure.vars = c("change_CS", "n_trips_alt"),
variable.name = "metric",
value.name = "value"
)
model_output1_long[, metric := fifelse(metric == "change_CS", "CV",
fifelse(metric == "n_trips_alt", "predicted trips", "metric"))]
model_output1_long$species<-"NA"
## Compute catch weight estimates
# Process length-frequency data
## Identify the length columns
pattern_vars <- grep(
"^keep_(sf_|bsb_|scup_)[0-9.]*$|^release_(sf_|bsb_|scup_)[0-9.]*$",
names(length_data),
value = TRUE
)
## Select needed columns and add month
length_data1 <- length_data[, .SD, .SDcols = c("date_parsed", "mode", pattern_vars)]
length_data1[, month := lubridate::month(date_parsed)]
## Aggregate sums by mode + month
length_data1 <- length_data1[, lapply(.SD, sum),
by = .(mode, month),
.SDcols = pattern_vars]
## MELT to long
length_data1 <- melt(
length_data1,
id.vars = c("month", "mode"),
variable.name = "Var",
value.name = "number_at_length"
)
## Split Var into keep_release, species, length
length_data1[, c("keep_release", "species", "length") := tstrsplit(Var, "_", fixed = TRUE)]
length_data1[, length := as.numeric(length)]
## Join with l_w_conversion
setDT(l_w_conversion)
length_data1 <- l_w_conversion[length_data1, on = .(month, species)]
## Compute weight
length_data1[, weight := fcase(
species == "scup", exp(ln_a + b * log(length)),
species %chin% c("sf", "bsb"), a * length^b,
default = NA_real_
)]
## Convert to lbs
length_data1[, weight := weight * 2.20462262185]
## Totals
length_data1[, keep_weight := fifelse(keep_release == "keep",
number_at_length * weight,
0)]
length_data1[, release_weight := fifelse(keep_release == "release",
number_at_length * weight,
0)]
length_data1[, keep_numbers := fifelse(keep_release == "keep",
number_at_length,
0)]
length_data1[, release_numbers := fifelse(keep_release == "release",
number_at_length,
0)]
## Discard mortality weight
length_data1[, discmort_weight := fcase(
keep_release == "release" & species == "sf", 0.10 * number_at_length * weight,
keep_release == "release" & species == "scup", 0.15 * number_at_length * weight,
keep_release == "release" & species == "bsb", 0.15 * number_at_length * weight,
default = 0
)]
## Discard mortality numbers
length_data1[, discmort_number := fcase(
keep_release == "release" & species == "sf", 0.10 * number_at_length,
keep_release == "release" & species == "scup", 0.15 * number_at_length,
keep_release == "release" & species == "bsb", 0.15 * number_at_length,
default = 0
)]
## Summarise by species, mode
length_data1 <- length_data1[, .(
keep_numbers = sum(keep_numbers),
release_numbers = sum(release_numbers),
keep_weight = sum(keep_weight),
release_weight = sum(release_weight),
discmort_weight = sum(discmort_weight),
discmort_number = sum(discmort_number)
), by = .(species, mode)]
length_data_long <- melt(
length_data1,
id.vars = c("species", "mode"),   # keep these as identifiers
measure.vars = c("keep_numbers", "release_numbers",
"keep_weight", "release_weight",
"discmort_weight", "discmort_number"),
variable.name = "metric",
value.name = "value"
)
## Remove NAs
length_data_long <- length_data_long[!is.na(value)]
## Split and classify
length_data_long_all <- length_data_long[, .(value = sum(value)),
by = .(metric, species)]
length_data_long_all[, mode := "all modes"]
## Final bind
length_output <- rbindlist(list(length_data_long_all, length_data_long) ,
use.names = TRUE,
fill = TRUE
)
predictions <- rbindlist(
list(length_output, model_output1_long),
use.names = TRUE,
fill = TRUE) %>%
dplyr::mutate(state = st, draw=dr)
predictions<-predictions %>%
dplyr::mutate(state=st, draw=dr)
print("Finished predict_rec_catch")
return(predictions)
predictions_list[[k]]<-predictions
View(predictions_list)
iterative_input_data_cd="E:/Lou's projects/flukeRDM/flukeRDM_iterative_data"
input_data_cd="C:/Users/andrew.carr-harris/Desktop/MRIP_data_2025"
predictions_list<-list()
k<-1
#for (st in c("MA", "RI", "CT", "NY", "NJ", "DE", "MD", "VA", "NC")){
for (st in c("MA","RI")){
for (dr in 1:2){
k<-k+1
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_data_read_test2.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/sim/predict_rec_catch_functions.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_test2.R")
predictions_list[[k]]<-predictions
}
}
View(predictions_list)
predictions_list2<-predictions_list[-1]
prediction_draws <- dplyr::bind_rows(predictions_list2)
View(prediction_draws)
View(prediction_draws)
# Status quo regs
predictions_list<-list()
k<-1
#for (st in c("MA", "RI", "CT", "NY", "NJ", "DE", "MD", "VA", "NC")){
for (st in c("MA", "RI", "CT")){
for (dr in 1:25){
k<-k+1
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_data_read_test2.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/sim/predict_rec_catch_functions.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_test2.R")
predictions_list[[k]]<-predictions
}
}
# Status quo regs
predictions_list<-list()
k<-1
#for (st in c("MA", "RI", "CT", "NY", "NJ", "DE", "MD", "VA", "NC")){
for (st in c("MA", "RI", "CT")){
for (dr in 1:2){
k<-k+1
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_data_read_test2.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/sim/predict_rec_catch_functions.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_test2.R")
predictions_list[[k]]<-predictions
}
}
predictions_list2<-predictions_list[-1]
prediction_draws <- dplyr::bind_rows(predictions_list2)
View(predictions_list)
View(prediction_draws)
# Reduce the minimum size by two for all species
predictions_list<-list()
k<-1
#for (st in c("MA", "RI", "CT", "NY", "NJ", "DE", "MD", "VA", "NC")){
for (st in c("MA", "RI")){
for (dr in 1:2){
k<-k+1
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_data_read_test2_min_minus2.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/sim/predict_rec_catch_functions.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_test2.R")
predictions_list[[k]]<-predictions
}
}
predictions_list2<-predictions_list[-1]
prediction_draws <- dplyr::bind_rows(predictions_list2)
# Status quo regs
predictions_list<-list()
k<-1
for (st in c("MA", "RI", "CT", "NY", "NJ", "DE", "MD", "VA", "NC")){
for (dr in 1:25){
k<-k+1
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_data_read_test2.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/sim/predict_rec_catch_functions.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_test2.R")
predictions_list[[k]]<-predictions
}
}
predictions_list2<-predictions_list[-1]
prediction_draws <- dplyr::bind_rows(predictions_list2)
prediction_draws_check <- prediction_draws %>%
dplyr::filter(is.na(value))
saveRDS(prediction_draws, file = file.path(iterative_input_data_cd, "test2output_SQ.rds"))
# Reduce the minimum size by two for all species
predictions_list<-list()
k<-1
for (st in c("MA", "RI", "CT", "NY", "NJ", "DE", "MD", "VA", "NC")){
for (dr in 1:25){
k<-k+1
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_data_read_test2_min_minus2.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/sim/predict_rec_catch_functions.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_test2.R")
predictions_list[[k]]<-predictions
}
}
predictions_list2<-predictions_list[-1]
prediction_draws <- dplyr::bind_rows(predictions_list2)
prediction_draws_check <- prediction_draws %>%
dplyr::filter(is.na(value))
saveRDS(prediction_draws, file = file.path(iterative_input_data_cd, "test2output_minus2.rds"))
# Increase the minimum size by two for all species
predictions_list<-list()
k<-1
for (st in c("MA", "RI", "CT", "NY", "NJ", "DE", "MD", "VA", "NC")){
for (dr in 1:25){
k<-k+1
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_data_read_test2_min_plus2.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/sim/predict_rec_catch_functions.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_test2.R")
predictions_list[[k]]<-predictions
}
}
predictions_list2<-predictions_list[-1]
prediction_draws <- dplyr::bind_rows(predictions_list2)
prediction_draws_check <- prediction_draws %>%
dplyr::filter(is.na(value))
saveRDS(prediction_draws, file = file.path(iterative_input_data_cd, "test2output_plus2.rds"))
sq<-readRDS(file.path(iterative_input_data_cd, "test2output_SQ.rds"))
write_csv(sq, file.path(iterative_input_data_cd, "test2output_SQ.csv"))
minus2<-readRDS(file.path(iterative_input_data_cd, "test2output_minus2.rds"))
write_csv(sq, file.path(iterative_input_data_cd, "test2output_minus2.csv"))
plus2<-readRDS(file.path(iterative_input_data_cd, "test2output_plus2.rds"))
write_csv(sq, file.path(iterative_input_data_cd, "test2output_plus2.csv"))
#Lou's repos
iterative_input_data_cd="E:/Lou's projects/flukeRDM/flukeRDM_iterative_data"
input_data_cd="C:/Users/andrew.carr-harris/Desktop/MRIP_data_2025"
# Status quo regs
predictions_list<-list()
k<-1
for (st in c("MA", "RI", "CT", "NY", "NJ", "DE", "MD", "VA", "NC")){
for (dr in 1:25){
k<-k+1
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_data_read_test2.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/sim/predict_rec_catch_functions.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_test2.R")
predictions_list[[k]]<-predictions
}
}
#Lou's repos
iterative_input_data_cd="E:/Lou's projects/flukeRDM/flukeRDM_iterative_data"
input_data_cd="C:/Users/andrew.carr-harris/Desktop/MRIP_data_2025"
# Status quo regs
predictions_list<-list()
k<-1
for (st in c("MA", "RI", "CT", "NY", "NJ", "DE", "MD", "VA", "NC")){
for (dr in 1:25){
k<-k+1
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_data_read_test2.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/sim/predict_rec_catch_functions.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_test2.R")
predictions_list[[k]]<-predictions
}
}
directed_trips<-feather::read_feather(file.path(iterative_input_data_cd, paste0("directed_trips_calibration_new/directed_trips_calibration_new_", st, ".feather"))) %>%
tibble::tibble()
View(directed_trips)
directed_trips_md <- directed_trips[mode == md]
#Lou's repos
iterative_input_data_cd="E:/Lou's projects/flukeRDM/flukeRDM_iterative_data"
input_data_cd="C:/Users/andrew.carr-harris/Desktop/MRIP_data_2025"
iterative_input_data_cd="E:/Lou's projects/flukeRDM/flukeRDM_iterative_data"
input_data_cd="C:/Users/andrew.carr-harris/Desktop/MRIP_data_2025"
#check
############# To Run Individual
# Variables to change
#dr<-1
#st="NJ"
ndraws=50 #number of choice occasions to simulate per strata
library(magrittr)
############# To Run in Loop
#for (st in c("MA", "RI", "CT", "NY", "NJ", "DE", "MD", "VA", "NC")){
#  for (dr in 1:2){
# import necessary data
# For kim: We need to retain the SQ regulation variables.
#          As of now, the SQ regulations variables are the ones without subscripts.
#          I will copy these variables with the subscript _SQ to make this explicit.
#          The alternative regulations that will be adjusted by the users will be
#          have subscripts _y2 (note this is slightly different from cod and haddock 2024)
directed_trips<-feather::read_feather(file.path(iterative_input_data_cd, paste0("directed_trips_calibration_new/directed_trips_calibration_new_", st, ".feather"))) %>%
tibble::tibble() %>%
dplyr::filter(draw == dr) %>%
dplyr::select(mode, date,
bsb_bag, bsb_min, bsb_bag_y2, bsb_min_y2,
fluke_bag, fluke_min, fluke_bag_y2,fluke_min_y2,
scup_bag, scup_min, scup_bag_y2, scup_min_y2) %>%
dplyr::mutate(
bsb_min_y2 = dplyr::if_else(
# Condition: bsb_bag > 0
bsb_bag > 0,
# Value if TRUE: add 2
bsb_min_y2 + 2*2.54,
# Value if FALSE: keep the original value
bsb_min_y2),
scup_min_y2 = dplyr::if_else(
# Condition: bsb_bag > 0
scup_bag > 0,
# Value if TRUE: add 2
scup_min_y2 + 2*2.54,
# Value if FALSE: keep the original value
scup_min_y2),
fluke_min_y2 = dplyr::if_else(
# Condition: bsb_bag > 0
fluke_bag > 0,
# Value if TRUE: add 2
fluke_min_y2 + 2*2.54,
# Value if FALSE: keep the original value
fluke_min_y2),
fluke_min_SQ=fluke_min, fluke_bag_SQ=fluke_bag,
bsb_min_SQ=bsb_min, bsb_bag_SQ=bsb_bag,
scup_min_SQ=scup_min, scup_bag_SQ=scup_bag)
st<-"NJ"
dr<-1
iterative_input_data_cd="E:/Lou's projects/flukeRDM/flukeRDM_iterative_data"
input_data_cd="C:/Users/andrew.carr-harris/Desktop/MRIP_data_2025"
#check
############# To Run Individual
# Variables to change
#dr<-1
#st="NJ"
ndraws=50 #number of choice occasions to simulate per strata
library(magrittr)
############# To Run in Loop
#for (st in c("MA", "RI", "CT", "NY", "NJ", "DE", "MD", "VA", "NC")){
#  for (dr in 1:2){
# import necessary data
# For kim: We need to retain the SQ regulation variables.
#          As of now, the SQ regulations variables are the ones without subscripts.
#          I will copy these variables with the subscript _SQ to make this explicit.
#          The alternative regulations that will be adjusted by the users will be
#          have subscripts _y2 (note this is slightly different from cod and haddock 2024)
directed_trips<-feather::read_feather(file.path(iterative_input_data_cd, paste0("directed_trips_calibration_new/directed_trips_calibration_new_", st, ".feather"))) %>%
tibble::tibble() %>%
dplyr::filter(draw == dr) %>%
dplyr::select(mode, date,
bsb_bag, bsb_min, bsb_bag_y2, bsb_min_y2,
fluke_bag, fluke_min, fluke_bag_y2,fluke_min_y2,
scup_bag, scup_min, scup_bag_y2, scup_min_y2) %>%
dplyr::mutate(
bsb_min_y2 = dplyr::if_else(
# Condition: bsb_bag > 0
bsb_bag > 0,
# Value if TRUE: add 2
bsb_min_y2 + 2*2.54,
# Value if FALSE: keep the original value
bsb_min_y2),
scup_min_y2 = dplyr::if_else(
# Condition: bsb_bag > 0
scup_bag > 0,
# Value if TRUE: add 2
scup_min_y2 + 2*2.54,
# Value if FALSE: keep the original value
scup_min_y2),
fluke_min_y2 = dplyr::if_else(
# Condition: bsb_bag > 0
fluke_bag > 0,
# Value if TRUE: add 2
fluke_min_y2 + 2*2.54,
# Value if FALSE: keep the original value
fluke_min_y2),
fluke_min_SQ=fluke_min, fluke_bag_SQ=fluke_bag,
bsb_min_SQ=bsb_min, bsb_bag_SQ=bsb_bag,
scup_min_SQ=scup_min, scup_bag_SQ=scup_bag)
catch_data <- feather::read_feather(file.path(iterative_input_data_cd, paste0("proj_catch_draws_feather/proj_catch_draws_",st, "_", dr,".feather"))) %>%
dplyr::left_join(directed_trips, by=c("mode", "date"))
#Lou's repos
iterative_input_data_cd="E:/Lou's projects/flukeRDM/flukeRDM_iterative_data"
input_data_cd="C:/Users/andrew.carr-harris/Desktop/MRIP_data_2025"
# Status quo regs
predictions_list<-list()
k<-1
#for (st in c("MA", "RI", "CT", "NY", "NJ", "DE", "MD", "VA", "NC")){
for (st in c( "NJ")){
for (dr in 1:5){
k<-k+1
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_data_read_test2.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/sim/predict_rec_catch_functions.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_test2.R")
predictions_list[[k]]<-predictions
}
}
predictions_list2<-predictions_list[-1]
prediction_draws <- dplyr::bind_rows(predictions_list2)
prediction_draws_check <- prediction_draws %>%
dplyr::filter(is.na(value))
#saveRDS(prediction_draws, file = file.path(iterative_input_data_cd, "test2output_SQ.rds"))
write_csv(prediction_draws, file.path(iterative_input_data_cd, "test2output_SQ_new.csv"))
# Reduce the minimum size by two for all species
predictions_list<-list()
k<-1
for (st in c( "NJ")){
for (dr in 1:5){
k<-k+1
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_data_read_test2_min_minus2.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/sim/predict_rec_catch_functions.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_test2.R")
predictions_list[[k]]<-predictions
}
}
predictions_list2<-predictions_list[-1]
prediction_draws <- dplyr::bind_rows(predictions_list2)
prediction_draws_check <- prediction_draws %>%
dplyr::filter(is.na(value))
#saveRDS(prediction_draws, file = file.path(iterative_input_data_cd, "test2output_minus2.rds"))
write_csv(prediction_draws, file.path(iterative_input_data_cd, "test2output_minus2_new.csv"))
# Increase the minimum size by two for all species
predictions_list<-list()
k<-1
for (st in c( "NJ")){
for (dr in 1:5){
k<-k+1
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_data_read_test2_min_plus2.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/sim/predict_rec_catch_functions.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_test2.R")
predictions_list[[k]]<-predictions
}
}
predictions_list2<-predictions_list[-1]
prediction_draws <- dplyr::bind_rows(predictions_list2)
prediction_draws_check <- prediction_draws %>%
dplyr::filter(is.na(value))
#saveRDS(prediction_draws, file = file.path(iterative_input_data_cd, "test2output_plus2.rds"))
write_csv(prediction_draws, file.path(iterative_input_data_cd, "test2output_plus2_new.csv"))
#Lou's repos
iterative_input_data_cd="E:/Lou's projects/flukeRDM/flukeRDM_iterative_data"
input_data_cd="C:/Users/andrew.carr-harris/Desktop/MRIP_data_2025"
# Status quo regs
predictions_list<-list()
k<-1
for (st in c("MA", "RI", "CT", "NY", "NJ", "DE", "MD", "VA", "NC")){
for (dr in 1:25){
k<-k+1
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_data_read_test2.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/sim/predict_rec_catch_functions.R")
source("C:/Users/andrew.carr-harris/Desktop/Git/flukeRDM/Code/test_code/predict_rec_catch_test2.R")
predictions_list[[k]]<-predictions
}
}
View(predictions_list)
